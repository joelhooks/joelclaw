---
title: "Self-Hosting Inngest: A Background Task Manager for AI Agents"
date: "2026-02-18"
type: "tutorial"
description: "Durable workflows on your Mac. Each step retries independently. Self-hosted, zero cloud dependencies. Your agent's nervous system."
---

## Set it up

```bash
# Start the server (30 seconds to dashboard)
docker run -d --name inngest \
  -p 8288:8288 \
  -v inngest-data:/var/lib/inngest \
  --restart unless-stopped \
  inngest/inngest:latest \
  inngest start --host 0.0.0.0

# Open the dashboard
open http://localhost:8288
```

One Docker container. Dashboard at `localhost:8288`. That's the whole infrastructure.

**For agents** — install the skill and it walks through the full setup adapted to your machine:

```bash
npx skills add joelhooks/joelclaw --skill inngest-local --yes --global
```

**Or curl the setup script:**

```bash
curl -fsSL https://joelclaw.com/scripts/inngest-setup.sh | bash
```

{/* TODO: Video — "Self-Hosting Inngest in 10 Minutes"
Pitch: Screen recording walkthrough. Start with empty Mac terminal.
1. docker run inngest (30 seconds to dashboard)
2. bun init a worker, write one function with two steps
3. Send an event, watch it execute step-by-step in dashboard
4. Kill the worker mid-function, restart, show it resume from last step
5. Set up launchd so it survives reboots
6. Show the claim-check pattern for large data between steps
7. Show the Caddy+Tailscale trick to access dashboard from phone
Runtime: ~8-10 minutes. No slides, no narration preamble. Terminal first frame.
*/}

---

## Why

You know this failure mode.

A script dies at minute 27 and you rerun the whole thing. An agent loop hums for 30 minutes and you keep the terminal open like a life support machine.<Sidenote id="sn-terminal-life">I lost an 8-story coding loop this way. Agent was on story 6 of 8. Closed the lid, machine slept, loop died. The first 5 stories were committed but the retry logic didn't exist yet.</Sidenote> A video download succeeds, transcription crashes, and you lose the good part.

**Durable workflows fix all of these.** Each step in a function retries independently. The machine reboots, the job picks up where it left off. Self-hosting means your data stays on your machine.<MarginNote id="mn-selfhost">Inngest Cloud exists and is great. I self-host because the data includes code diffs, transcripts, and agent conversations I don't want leaving my network.</MarginNote>

## What it is

[Inngest](https://www.inngest.com/) is an event-driven workflow engine. You send an event, a function runs, that function is broken into steps. If step 2 fails, step 1 does **not** run again.

Self-hosted = one Docker container (the server) + your worker process (Bun/Node). Dashboard at `localhost:8288` shows every event, every step, every retry.

## What happens when you set this up

```
docker run → Inngest server + dashboard (localhost:8288)
bun run   → your worker registers functions
curl      → send events, functions execute durably
launchd   → everything survives reboots
```

## What I run on this

Fourteen functions. Two pipelines. The full architecture is in [Inngest is the Nervous System](/inngest-is-the-nervous-system).

**Video ingest pipeline:** YouTube URL → yt-dlp download → NAS archive → mlx-whisper transcription → vault note → AI enrichment. Five steps across three tools. Any step retries independently.

**Autonomous coding loops:** A PRD goes in, committed code comes out. Planner → Implementor → Reviewer → Judge → Retrospective. Each role is a separate function run with its own retry policy and timeout.

**Heartbeat cron:** Every 15 minutes, prunes stale sessions, audits trigger registrations, pushes a gateway event. The [gateway](/building-a-gateway-for-your-ai-agent) picks it up.

## Patterns that matter

**Event chaining** — function A emits an event that triggers function B. No orchestrator holding state. Inngest replays from the last completed step if anything crashes.

**Claim-check** — step outputs have a size limit. Write large data to a file, pass the path. The transcribe step writes a 1MB transcript to `/tmp`, returns just the filepath.

**Concurrency keys** — `concurrency: { key: "event.data.project", limit: 1 }`. One coding loop per project. One transcription at a time (GPU saturation).<Sidenote id="sn-gpu-sat">mlx-whisper saturates the Apple Silicon GPU. Running two transcriptions concurrently doesn't error — it just makes both take 3x longer. Concurrency limit of 1 is the right call.</Sidenote> Multiple downloads in parallel.

## Gotchas I hit

**The k8s naming collision.** A Service named `inngest` creates an `INNGEST_PORT` env var. The Inngest binary also uses `INNGEST_PORT` — expects an integer, gets `tcp://10.43.x.x:8288`.<Sidenote id="sn-k8s-naming">Kubernetes auto-creates `{SERVICE_NAME}_PORT` env vars for every Service. If your Service name collides with an env var the binary expects, you get silent misconfig. Name your Service `inngest-svc` or similar. This is a rite of passage.</Sidenote> Two characters: name it `inngest-svc`. Thirty minutes of debugging.

**Trigger drift.** Functions register triggers at startup. Server state can drift from code. Triggers silently break. I built an auditor that runs every 15 minutes and alerts on drift.

**Worker re-registration.** After Inngest server restart, the worker needs to re-register. `joelclaw refresh` or just restart the worker process.

## For humans

The deeper architecture narrative — why each decision was made, what the alternatives were, how the pieces compose — is in [Inngest is the Nervous System](/inngest-is-the-nervous-system) and [The One Where Joel Deploys Kubernetes... Again](/joel-deploys-k8s).

---

*This is a living document. Updated as the system evolves.*
