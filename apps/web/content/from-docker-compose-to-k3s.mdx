---
title: "From Docker Compose to k3s in One Session"
date: "2026-02-16"
description: "Three containers and a spike that turned into a production migration. Why I moved my personal AI infrastructure to Kubernetes — and the gotchas nobody warns you about."
---

Three Docker Compose services. Redis, Qdrant, Inngest. Running on a Mac Mini for months. Working fine.

So why change anything?

## The trigger wasn't pain

The honest answer: I'm about to buy a Mac Studio. 128 GB unified memory. When it arrives, I want to run local LLM inference on it while the Mini handles everything else. Two machines, services on both. That's a scheduling problem, and Kubernetes solves scheduling problems.

But I don't want to learn Kubernetes under pressure on the day the Studio arrives. So I spiked it. Time-boxed experiment: can k3s run on this Mac Mini, what's the overhead, and how mechanical is the migration?

The spike worked. So I kept going.

## k3d, not k3s

k3s is Linux-only. My Mac runs macOS. The options:

| Approach | What it means |
|---|---|
| **k3d** | k3s inside Docker (already running Docker Desktop) |
| OrbStack | Lightweight alternative to Docker Desktop |
| Lima VM | Separate Linux VM to manage |
| Control plane on a Linux box | Mac is agent-only |

k3d wins because Docker Desktop is already running. One dependency I already pay for. No new VMs, no new abstractions.

```bash
k3d cluster create joelclaw \
  --servers 1 \
  --port "6379:6379@server:0" \
  --port "6333:6333@server:0" \
  --port "8288:8288@server:0" \
  --k3s-arg "--disable=traefik@server:0" \
  --k3s-arg "--kube-apiserver-arg=service-node-port-range=80-32767@server:0" \
  --wait
```

Nineteen seconds to a running cluster.

## The INNGEST_PORT collision

First deploy. Redis comes up. Qdrant comes up. Inngest crashes immediately.

```
strconv.Atoi: parsing "tcp://10.43.53.131:8288": invalid syntax
```

This is a classic Kubernetes gotcha that nobody warns you about. When you create a Service named `inngest`, Kubernetes auto-injects environment variables into every pod in the namespace:

```
INNGEST_SERVICE_HOST=10.43.53.131
INNGEST_PORT=tcp://10.43.53.131:8288
```

The Inngest binary has its own `INNGEST_PORT` env var — expects an integer. Gets a URL. Crash.

**Fix**: name the Service `inngest-svc`. The env vars become `INNGEST_SVC_PORT` and the collision disappears. Two characters, thirty minutes of debugging.

[TODO: Joel — was this actually frustrating or more of an "oh, that's interesting" moment?]

## The NodePort range gotcha

Kubernetes default NodePort range is 30000-32767. My services need ports 6379, 6333, and 8288. You have to tell k3s at cluster creation:

```
--kube-apiserver-arg=service-node-port-range=80-32767
```

And here's the thing about k3d: **cluster config is immutable after creation.** Port mappings, k3s args, everything is locked at `cluster create` time. If you forget a port or a flag, you delete the cluster and start over.

Plan your ports before you create.

## The manifests are boring (that's the point)

Each Docker Compose service became a StatefulSet + NodePort Service. Same images, same commands, same health checks. The translation is mechanical:

| Docker Compose | k8s |
|---|---|
| `image: redis:7-alpine` | `image: redis:7-alpine` |
| `volumes: redis_data:/data` | `volumeClaimTemplates` with PVC |
| `ports: "6379:6379"` | NodePort service on 6379 |
| `restart: unless-stopped` | StatefulSet (always restarts) |
| `healthcheck` | `livenessProbe` + `readinessProbe` |

StatefulSets because all three services need stable storage. Deployments would work for stateless things, but Redis with AOF, Qdrant with its index, and Inngest with SQLite all need their data to survive pod restarts.

## The overhead

| What | Memory |
|---|---|
| k3s control plane + system services | ~587 MB |
| Redis pod | 9 MB |
| Qdrant pod | 273 MB |
| Inngest pod | 46 MB |
| **Total** | **~915 MB** |

For comparison, Docker Compose was 536 MB for the same three services. The k8s tax is ~380 MB — the control plane, CoreDNS, metrics-server, the local-path provisioner. On a 64 GB machine that's 0.6% overhead for a real orchestrator.

The pods themselves actually use *less* memory inside k3s than they did in Docker Compose. Not sure why. Didn't investigate.

## The cutover

The spike ran alongside Docker Compose — different ports, both stacks operational. Once everything checked out:

1. Stop Docker Compose (free the ports)
2. Recreate k3d cluster with production port mappings
3. Deploy manifests
4. Restart the worker (still runs on the host via launchd)
5. Re-register worker with the new Inngest instance
6. Smoke test: send an event, watch it complete

The worker didn't need a single config change. It still connects to `localhost:6379`, `localhost:6333`, `localhost:8288` — same as before. The ports are just served by k8s NodePorts instead of Docker port bindings.

`docker compose down`. Done.

## What stays on launchd

The system-bus worker runs on the host, not in k8s. It needs direct filesystem access — git operations on the Vault, Whisper transcription using the Mac's GPU, reading and writing to paths all over the machine. Containerizing it would mean mounting half the filesystem into a pod.

Caddy stays on launchd too. It terminates TLS with Tailscale certificates that live on the host.

Both are fine where they are. Not everything needs to be in a cluster.

## What this unlocks

When the Mac Studio arrives:

```bash
# On the Studio
k3d cluster create joelclaw --servers 1 ...
# Join the Mini as an agent
k3d cluster create ... --agents 1 ...
```

[TODO: Joel — the actual multi-node k3d setup is more nuanced than this, might want to revisit when it's real]

Two nodes. `kubectl get pods -A` shows everything running across both machines. Health checks, restarts, scheduling — handled. The [ADR-0025](/adrs/0025-k3s-cluster-for-joelclaw-network) lays out the full phased plan.

For now it's one Mac Mini running a single-node k3s cluster with three StatefulSets. Simple. But the migration path to two nodes, then three, then a GPU box — it's all just `kubectl apply`.

---

*This is part of a series about building a personal AI system. Previous: [Inngest is the Nervous System](/inngest-is-the-nervous-system). The [network page](/network) shows the current cluster state.*
