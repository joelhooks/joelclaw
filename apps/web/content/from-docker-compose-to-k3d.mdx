---
title: "The One Where Joel Deploys Kubernetes"
date: "2026-02-16"
description: "Three containers and a spike that turned into a production migration. Why I moved my personal AI infrastructure from Docker Compose to k3d â€” and the gotchas nobody warns you about."
draft: true
---

> **ðŸŒ± This is a draft.** The single-node migration happened and works. I'm still thinking through the multi-node story â€” where the control plane lives and what runtime replaces k3d when a second machine needs to join.

I deployed Kubernetes to run three containers on a Mac Mini in my office.

Three. Redis, Qdrant, Inngest. They were running fine in Docker Compose. Nobody asked for this.

But I want to add more machines to the network and distribute workloads across them. Docker Compose doesn't do that. The moment you want to schedule a job on a different node, or health-check services across machines, or route inference to a GPU box â€” you need an orchestrator. That's what Kubernetes is.

Whether three containers on a single machine justifies Kubernetes is a question I've decided not to think too hard about. The manifests are the same whether it's one node or five.

I spiked it. The spike worked. So I kept going. The whole migration was one session.

## Nineteen seconds to a cluster

k3d runs k3s inside Docker â€” which is already running on this machine. No new VMs, no new dependencies. Docker Desktop is free for personal use, so the only thing I added was the `k3d` binary. The portable layer is the k8s manifests â€” same `kubectl apply` whether it's k3d on macOS or native k3s on Linux.

```bash
k3d cluster create joelclaw \
  --servers 1 \
  --port "6379:6379@server:0" \
  --port "6333:6333@server:0" \
  --port "8288:8288@server:0" \
  --k3s-arg "--disable=traefik@server:0" \
  --k3s-arg "--kube-apiserver-arg=service-node-port-range=80-32767@server:0" \
  --wait
```

Nineteen seconds. Three StatefulSets later, everything's running.

## The gotchas nobody warns you about

**The service naming collision.** First deploy â€” Redis comes up, Qdrant comes up, Inngest crashes:

```
strconv.Atoi: parsing "tcp://10.43.53.131:8288": invalid syntax
```

Kubernetes auto-injects environment variables based on Service names. A Service named `inngest` creates `INNGEST_PORT=tcp://10.43.x.x:8288`. The Inngest binary has its own `INNGEST_PORT` â€” expects an integer. Gets a URL. Crash. Fix: name the Service `inngest-svc`. Two characters, thirty minutes of debugging.

Never name a k8s Service the same as the binary it runs.

**The NodePort range.** Default is 30000-32767. My services need 6379, 6333, 8288. You set `--service-node-port-range=80-32767` at cluster creation.

**k3d is immutable after creation.** Port mappings, k3s args â€” all locked at `cluster create` time. Forget a port, delete the cluster, start over. I recreated it three times. Plan your ports first.

## The overhead

The k8s tax is ~380 MB for the control plane, CoreDNS, metrics-server, and the storage provisioner. Total for everything â€” control plane plus all three services â€” is about 915 MB. Docker Compose was 536 MB for the same three services. On a 64 GB machine that's 0.6% overhead for a real orchestrator.

The cutover was anticlimactic. Stop Compose, deploy manifests, restart the worker. The worker still connects to `localhost:6379`, `localhost:6333`, `localhost:8288` â€” same as before. The ports are just served by k8s NodePorts now instead of Docker port bindings. `docker compose down`. Done.

Not everything moved. The system-bus worker stays on launchd â€” it needs the host filesystem for git, Whisper transcription, and writing all over the machine. Caddy stays too. Not everything needs to be in a cluster.

## Why k3d

I looked at the homelab landscape before committing.

**k3d** wraps k3s inside Docker containers. Since Docker Desktop is already running on this Mac, k3d adds zero new infrastructure â€” no VMs, no Multipass, no new daemon. Cluster up in 19 seconds, cluster down in 3. The catch: it's single-machine only. k3d nodes are containers on one host â€” remote machines can't join the cluster.

**microk8s** runs in a Multipass VM on macOS (~4 GB RAM, comparable to Docker Desktop's own VM). It *can* do multi-node â€” remote microk8s instances join via `microk8s add-node`. But Multipass has known disk I/O issues on Apple Silicon, and you're paying VM overhead for something Docker already does.

**Talos Linux** is the rising star â€” an immutable OS that *is* the cluster. No SSH, no package manager, API-driven. Compelling for dedicated Linux nodes but replaces the entire OS, which doesn't work alongside macOS.

**Nomad** by HashiCorp was interesting until they relicensed it to BSL. The community is migrating away.

k3d wins for single-machine k8s on a Mac that's already running Docker. If a second machine needs to join, that's a different decision â€” probably native k3s on Linux, or OrbStack on Mac. The manifests are portable. The [network page](/network) shows the current state.

## Appendix: does it have to be Kubernetes

No. Here's the real landscape:

| Approach | Good at | Bad at |
|---|---|---|
| **k3d / k3s / k8s** | Automatic scheduling, health checks, GPU routing, self-healing | YAML, complexity, learning curve |
| **Kamal** (37signals) | Dead simple deploys, zero-downtime | You're the scheduler â€” you decide what runs where |
| **Ansible + Docker Compose** | Familiar, idempotent, no runtime daemon | No live scheduling, no cross-node failover |
| **Nomad** | Simpler than k8s, containers + VMs + batch | BSL licensed, community leaving, needs Consul + Vault |
| **systemd + Podman** | Zero overhead, OS-native | No cross-machine anything |
| **Docker Swarm** | Built into Docker | Basically abandoned |
| **Talos Linux** | No OS to manage, API-driven | Replaces the entire OS |
| **NixOS** | Reproducible machine state, atomic rollbacks | Different paradigm entirely |

The real question: do you need a **runtime scheduler** or **declarative deployment**?

A runtime scheduler â€” k8s, Nomad â€” decides where things run. "This pod needs a GPU, figure it out." Handles failures automatically.

Declarative deployment â€” Kamal, Ansible â€” puts things where you tell it. Simpler, but you're the scheduler.

For three services on one machine, Kamal works fine. The moment you want heterogeneous nodes â€” GPU jobs to the GPU box, stateful services on the Mac, batch work wherever there's capacity â€” you need a scheduler. That's the bet.

Kamal is the off-ramp if this ever feels like too much.

---

*This is part of a series about building a personal AI system. Previous: [Inngest is the Nervous System](/inngest-is-the-nervous-system).*
