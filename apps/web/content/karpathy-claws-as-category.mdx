---
title: "Karpathy Says We're Building \"Claws\""
type: "note"
date: "2026-02-21T08:00:00"
description: "Andrej Karpathy bought a Mac Mini to tinker with Claws. Simon Willison thinks 'Claw' is becoming a term of art. I think they're both right â€” and joelclaw has been one this whole time."
tags: ["claws", "openclaw", "terminology"]
source: "https://simonwillison.net/2026/Feb/21/claws/"
---

[Simon Willison flagged](https://simonwillison.net/2026/Feb/21/claws/) an Andrej Karpathy tweet that caught my attention. Karpathy bought a Mac Mini â€” apparently Apple stores are "selling like hotcakes and everyone is confused" â€” to tinker with what he's calling **Claws**.

His definition:

> Just like LLM agents were a new layer on top of LLMs, Claws are now a new layer on top of LLM agents, taking the orchestration, scheduling, context, tool calls and a kind of persistence to a next level.

That's... exactly what I've been building. joelclaw is a Claw by this definition and I didn't know the word existed until today.

## The security argument for building your own

Karpathy is blunt about OpenClaw specifically:

> Giving my private data/keys to 400K lines of vibe coded monster that is being actively attacked at scale is not very appealing at all. Already seeing reports of exposed instances, RCE vulnerabilities, supply chain poisoning, malicious or compromised skills in the registry.

This is why I [built my own](/building-my-own-openclaw) instead of deploying OpenClaw. When a system has access to your keys, your files, your email, your calendar â€” the attack surface isn't theoretical. A compromised skill in the registry can exfiltrate everything. A 400K-line codebase that grew at 6,600 commits/month is not something any human has audited.

Building from scratch means I know every line. The system-bus, the gateway, the memory pipeline â€” I wrote it (well, me and the agents). That's not just satisfying, it's a security posture.

## What makes a Claw a Claw

Karpathy doesn't give a formal spec, but reading between the lines plus Willison's gloss, a Claw is:

- **Runs on personal hardware** â€” Mac Mini, home server, your own metal
- **Communicates via messaging protocols** â€” Telegram, WhatsApp, SMS, voice
- **Handles both direct instructions and scheduled tasks** â€” you can tell it things AND it does things on its own
- **Orchestration + persistence** â€” not just a chat session that forgets everything

joelclaw checks every box. [Inngest for durable workflows](/inngest-is-the-nervous-system). [Gateway daemon](/building-a-gateway-for-your-ai-agent) for messaging. Qdrant + Redis + Vault for persistence. Cron heartbeats. Voice via LiveKit SIP. Todoist as async conversation channel. It's a Claw. It's been a Claw. We just didn't have the word.

## Skills as configuration

The NanoClaw detail that actually blew my mind: they don't use config files. Configuration is done via *skills*. `/add-telegram` instructs your AI agent how to modify the actual code to integrate Telegram. Not a YAML file. Not an environment variable. A skill that teaches the agent to fork the codebase.

Karpathy calls this "a new, AI-enabled approach to preventing config mess and if-then-else monsters." The meta becomes: write the most maximally forkable repo, then have skills that fork it into any desired configuration.

This is close to what [pi skills](https://github.com/mariozechner/pi-coding-agent) already do â€” SKILL.md files that teach the agent how to perform specialized tasks. But NanoClaw takes it further by making skills the *only* configuration mechanism. No config files at all. That's a strong opinion and I think it's mostly right.

## The proliferation

NanoClaw (~4,000 lines core engine, runs in containers), nanobot, zeroclaw, ironclaw, picoclaw â€” the prefix game is real. Plus cloud-hosted alternatives, though Karpathy doesn't love those because "it feels much harder to tinker with" and you lose local network access for home automation.

The architectural pattern is clear enough that implementations are converging independently. OpenClaw proved the idea works. Whether you run their code or build your own, you end up in roughly the same place.

## The "fits in your head" constraint

The NanoClaw detail that stuck with me: ~4,000 lines for the core engine, which "fits into both my head and that of AI agents." That's a real design constraint worth taking seriously. joelclaw's system-bus is larger than that, but it also does more â€” durable workflows, [multi-phase memory](/observation-pipeline-persistent-ai-memory), multi-channel gateway, [voice agent](/voice-agent-deployment-deep-dive).

The question isn't whether 4K lines is the right number. It's whether your agent can read its own source code and understand what it does. That's the bar for self-improvement. If the system is too complex for the agent to reason about, you've built a system the agent can use but never fix.

joelclaw can read its own code. It regularly does â€” codex sessions modify the system-bus, the gateway extension, the CLI. Whether it truly *understands* the full system is a different question. But the architecture is legible enough that agents can work on it. That matters more than line count.

## The name

"Claw" is good. It's short, it's concrete, it implies grabbing things and doing stuff. Better than "personal AI agent system" or "OpenClaw-inspired architecture." And ðŸ¦ž is a fine emoji.

Karpathy has an ear for this â€” he gave us "vibe coding" and "agentic engineering." Both stuck. I think "Claw" sticks too.

And his best line: "there is something aesthetically pleasing about there being a physical device 'possessed' by a little ghost of a personal digital house elf."

Yeah. That's joelclaw. A Mac Mini possessed by a house elf that reads my email, manages my tasks, transcribes my voice, and sometimes calls me on the phone to tell me it finished building something. ðŸ¦ž
